<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Cleaning on Zi Xun</title>
    <link>https://gary0417.github.io/Zi_Xun_Portfolio/tags/data-cleaning/</link>
    <description>Recent content in Data Cleaning on Zi Xun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Mar 2023 10:58:08 -0400</lastBuildDate><atom:link href="https://gary0417.github.io/Zi_Xun_Portfolio/tags/data-cleaning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Project 1: Bangalore House Price Prediction</title>
      <link>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-1/</link>
      <pubDate>Fri, 24 Mar 2023 10:58:08 -0400</pubDate>
      
      <guid>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-1/</guid>
      <description>🏠 Created a tool that estimates house prices in Bangalore, India, to help buyers and sellers make informed decisions.
🌳 Optimized Random Forest Regressors using RandomizedSearchCV to achieve the best possible performance.
🌐 Built a client-facing API using flask and a website using HTML, CSS, and JavaScript which allows users to input the features of a house (such as location, size, and number of bedrooms) and get an estimated price.</description>
    </item>
    
    <item>
      <title>Project 2: Naive Bayes Spam Filter</title>
      <link>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-2/</link>
      <pubDate>Fri, 24 Mar 2023 10:58:08 -0400</pubDate>
      
      <guid>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-2/</guid>
      <description>📧 Implemented a spam filter in Python using Naive Bayes from scratch (without the help of pandas and scikit-learn).
🔗 Link to GitHub Repository
Dataset SMS Spam Collection Data Set - UCI Machine Learning Repository
Data Preprocessing removed punctuation set all the letters to lower case split the senteces to distinct words randomised the dataset split the data into training data and test data separated spam SMS from ham SMS extracted the SMS from the data (removed the label) extracted all the words that appear in the SMS removed duplicates from the vocabulary Model Building Below are the steps I took to build the model:</description>
    </item>
    
  </channel>
</rss>
