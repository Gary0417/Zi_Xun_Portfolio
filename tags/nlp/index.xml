<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NLP on Zi Xun</title>
    <link>https://gary0417.github.io/Zi_Xun_Portfolio/tags/nlp/</link>
    <description>Recent content in NLP on Zi Xun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jun 2023 08:58:08 -0400</lastBuildDate><atom:link href="https://gary0417.github.io/Zi_Xun_Portfolio/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Project 5: Movie Recommendation Systems</title>
      <link>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-5/</link>
      <pubDate>Tue, 13 Jun 2023 08:58:08 -0400</pubDate>
      
      <guid>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-5/</guid>
      <description>ðŸŽ¥ This project aims to build a movie recommendation system using content-based filtering and collaborative filtering techniques. The script uses the Sentence Transformers library for content-based filtering and the Surprise library for collaborative filtering.
ðŸ”— Link to GitHub Repository
How it works The script first cleans and preprocesses the movie metadata, keywords, and ratings data. It then builds a content-based filtering system by creating a &amp;ldquo;soup&amp;rdquo; of text that includes the genres, original language, overview, tagline, keywords, and production countries for each movie.</description>
    </item>
    
    <item>
      <title>Project 4: Quora Insincere Questions Classification</title>
      <link>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-4/</link>
      <pubDate>Mon, 17 Apr 2023 10:58:08 -0400</pubDate>
      
      <guid>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-4/</guid>
      <description>ðŸ¤” This project aims to classify whether a question asked on Quora is sincere or not using pre-trained NLP text embedding models from TensorFlow Hub.
ðŸ”— Link to GitHub Repository
Data Preprocessing Class imbalance is treated with downsampling technique. The dataset is split into training and validation datasets with an 8:2 ratio. Model Building The text classification model is built using pre-trained NLP text embedding models from Tensorflow Hub. The model architecture consists of the hub layer which includes the pre-trained model from Tensorflow Hub, followed by Dropout layers (with a dropout rate of 0.</description>
    </item>
    
    <item>
      <title>Project 1: Naive Bayes Spam Filter</title>
      <link>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-1/</link>
      <pubDate>Fri, 24 Mar 2023 10:58:08 -0400</pubDate>
      
      <guid>https://gary0417.github.io/Zi_Xun_Portfolio/post/project-1/</guid>
      <description>ðŸ“§ Implemented a spam filter in Python using Naive Bayes from scratch (without the help of pandas and scikit-learn).
ðŸ”— Link to GitHub Repository
Dataset SMS Spam Collection Data Set - UCI Machine Learning Repository
Data Preprocessing removed punctuation set all the letters to lower case split the senteces to distinct words randomised the dataset split the data into training data and test data separated spam SMS from ham SMS extracted the SMS from the data (removed the label) extracted all the words that appear in the SMS removed duplicates from the vocabulary Model Building Below are the steps I took to build the model:</description>
    </item>
    
  </channel>
</rss>
